Erros:
    - Não encontra o caminho do dataset. Como corrigir? 
        - Colocar 'train', 'test' e 'valid' nos nomes dos arquivos de dataset
        - 'test' e 'valid' datasets tem que tá no mesmo diretório durante o modo de validação


Processar arquivos do dataset para lista de dicionários no formato json e salvar .json no diretório: /json_data
    - 
Em seguida, transformar para binários do pytorch com os comandos abaixo:
    short: python preprocess.py -pretrained_model bert-base-multilingual-uncased -mode format_to_bert -raw_path ../json_data -save_path ../bert_data  -lower -n_cpus 10 -log_file ../logs/preprocess.log
    full: python preprocess.py -pretrained_model bert-base-multilingual-uncased -mode format_to_bert -raw_path ../json_data -save_path ../bert_data  -lower -n_cpus 8 -log_file ../logs/preprocess.log -use_bert_basic_tokenizer=true -min_src_nsents 11 -max_src_nsents 400 -min_tgt_ntokens 150 

TransformerAbs (baseline) de dentro da pasta 'src': # Treino com o primeiro modelo, trocar BERT_MODEL_NAME com nome do modelo
    full: python train.py -task abs -mode train -accum_count 5 -batch_size 48 -bert_data_path ../bert_data -dec_dropout 0.1 -log_file ../logs/pt_br_baseline -lr 0.05 -model_path ../models -save_checkpoint_steps 2000 -use_interval true -seed 777 -sep_optim false -train_steps 200000 -use_bert_emb true -warmup_steps 8000  -visible_gpus 0,1,2,3 -max_pos 4000 -report_every 50 -enc_hidden_size 512  -enc_layers 6 -enc_ff_size 2048 -enc_dropout 0.1 -dec_layers 6 -dec_hidden_size 512 -dec_ff_size 2048 -encoder baseline
    short: python train.py -task abs -mode train -accum_count 5 -batch_size 4 -bert_data_path ../bert_data -dec_dropout 0.1 -log_file ../logs/cnndm_baseline -lr 0.05 -model_path ../models/baseline -save_checkpoint_steps 100 -use_interval true -seed 777 -sep_optim false -train_steps 200000 -use_bert_emb true -warmup_steps 8000  -visible_gpus 0 -max_pos 24 -report_every 50 -enc_hidden_size 24  -enc_layers 6 -enc_ff_size 96 -enc_dropout 0.1 -dec_layers 6 -dec_hidden_size 24 -dec_ff_size 96 -encoder baseline


BertAbs:
    full: python train.py -task abs -mode train -accum_count 5 -batch_size 140 -bert_data_path ../bert_data -dec_dropout 0.2  -log_file ../logs/abs_bert_cnndm -lr_bert 0.002 -model_path ../models -save_checkpoint_steps 2000 -use_interval true -sep_optim true -lr_dec 0.2 -train_steps 200000 -use_bert_emb true -warmup_steps_bert 20000 -visible_gpus 0 -warmup_steps_dec 10000 -max_pos 512 -report_every 50   
    short: python train.py -task abs -mode train -accum_count 5 -batch_size 4 -bert_data_path ../bert_data -dec_dropout 0.2  -log_file ../logs/abs_bert_cnndm -lr_bert 0.002 -model_path ../models -save_checkpoint_steps 100 -use_interval true -sep_optim true -lr_dec 0.2 -train_steps 20000 -use_bert_emb true -warmup_steps_bert 20000 -visible_gpus 0 -warmup_steps_dec 10000 -max_pos 512 -report_every 50


Avaliação:
    Baseline:
    short:  python train.py -task abs -mode validate -accum_count 5 -batch_size 4 -bert_data_path ../bert_data/valid -log_file ../logs/cnndm_baseline -model_path ../models/baseline -save_checkpoint_steps 2000 -use_interval true -seed 777 -sep_optim false -use_bert_emb true -warmup_steps 8000 -visible_gpus -1 -max_pos 24 -report_every 50 -encoder baseline

    BertAbs:
    full:  python train.py -task abs -mode validate -batch_size 3000 -test_batch_size 500 -bert_data_path ../bert_data -log_file ../logs/val_abs_bert_cnndm -model_path ../models -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm 
    short:  python train.py -task abs -mode validate -batch_size 4 -test_batch_size 500 -bert_data_path ../bert_data -log_file ../logs/val_abs_bert_cnndm -model_path ../models/baseline -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm 



##### Alteração do BERT #####

model_builder.py:
    - Carrega o modelo pre-treinado


train_abstractive.py:
    - Carrega o tokenizador e tem que conversar com o modelo carregado no model_builder
    - 